# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
ADMIN_TELEGRAM_USER_ID=your_telegram_user_id_here

# OpenRouter API Configuration
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1/chat/completions
MODEL_NAME=qwen/qwen3-235b-a22b-2507
TEMPERATURE=0.3
MAX_TOKENS=1000

# Alternative models (tested):
# MODEL_NAME=x-ai/grok-code-fast-1  # Backup option - slower but also 100% success
# MODEL_NAME=anthropic/claude-3.5-sonnet  # High quality translations
# MODEL_NAME=openai/gpt-4o  # Good balance of speed and quality

# Database Configuration
DATABASE_PATH=./data/qa_search.db

# Flask Configuration
FLASK_SECRET_KEY=change_this_to_a_random_secret_key
JWT_SECRET_KEY=change_this_to_another_random_secret_key
FLASK_ENV=production

# Server Configuration
PORT=5000
HOST=0.0.0.0

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log

# Optional
HTTP_REFERER=https://your-site.com
APP_TITLE=QA Search Interface

# JWT Configuration
JWT_ACCESS_TOKEN_EXPIRES=86400  # 24 hours in seconds

# Testing Credentials (DEVELOPMENT ONLY - REMOVE IN PRODUCTION!)
# Uncomment and set these for automatic test user creation
# TEST_USERNAME=testuser
# TEST_PASSWORD=testpass123

# Translation Configuration
TRANSLATION_BATCH_SIZE=10  # Number of QA pairs to translate per API request
TRANSLATION_CACHE_FILE=./data/translation_cache.json

# Parallel Translation (for translate_qa_parallel.py)
MAX_CONCURRENT_REQUESTS=20  # Number of parallel API requests (recommended: 10-30)
REQUESTS_PER_MINUTE=180     # Conservative rate limit (OpenRouter has no strict limit for paid models)
